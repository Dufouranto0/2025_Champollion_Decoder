{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: CINGULATE_right\n",
      "Numpy path: /neurospin/dico/data/deep_folding/current/datasets/UkBioBank40/crops/2mm/CINGULATE./mask/Rskeleton.npy\n",
      "Subjects path: /neurospin/dico/data/deep_folding/current/datasets/UkBioBank40/crops/2mm/CINGULATE./mask/Rskeleton_subject.csv\n",
      "subject column name: Subject\n",
      "Input size: (1, 16, 37, 37)\n"
     ]
    }
   ],
   "source": [
    "# Load decoder config\n",
    "decoder_cfg = OmegaConf.load(\"../configs/config.yaml\")\n",
    "\n",
    "# Load encoder's training config\n",
    "encoder_config_path = os.path.join(\n",
    "    decoder_cfg.model_to_decode_path,\n",
    "    \".hydra\",\n",
    "    \"config.yaml\"\n",
    ")\n",
    "encoder_cfg = OmegaConf.load(encoder_config_path)\n",
    "\n",
    "# Override dataset_folder which conains a mistake\n",
    "encoder_cfg[\"dataset_folder\"] = decoder_cfg[\"dataset_folder\"]\n",
    "\n",
    "# Only resolve the dataset part to avoid errors in unrelated keys\n",
    "region = list(encoder_cfg.dataset.keys())[0]\n",
    "print(\"Region:\", region)\n",
    "\n",
    "dataset_info = OmegaConf.to_container(encoder_cfg.dataset[region], resolve=True)\n",
    "\n",
    "# Access relevant dataset info\n",
    "\n",
    "print(\"Numpy path:\", dataset_info['numpy_all'])\n",
    "print(\"Subjects path:\", dataset_info['subjects_all'])\n",
    "print(\"subject column name:\", dataset_info['subject_column_name'])\n",
    "print(\"Input size:\", dataset_info['input_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CINGULATE_right (42433, 16, 37, 37, 1) 42433\n"
     ]
    }
   ],
   "source": [
    "skels = np.load(dataset_info['numpy_all'])\n",
    "list_sub = pd.read_csv(dataset_info['subjects_all'])\n",
    "print(region, skels.shape, len(list_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath = os.path.join(decoder_cfg[\"model_to_decode_path\"])\n",
    "train_path = os.path.join(rootpath, decoder_cfg[\"train_csv\"])\n",
    "val_test_path = os.path.join(rootpath, decoder_cfg[\"val_test_csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 38190\n",
      "Validation set size: 2092\n",
      "Test set size: 2151\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_path)\n",
    "a = pd.read_csv(val_test_path)\n",
    "a['IID'] = a['ID'].apply(lambda x : int(x[4:]))\n",
    "val_data = a[a['IID']%2 ==0].drop('IID', axis=1)\n",
    "test_data = a[a['IID']%2 ==1].drop('IID', axis=1)\n",
    "\n",
    "#train_data = train_data.drop('ID', axis=1)\n",
    "#val_data = val_data.drop('ID', axis=1)\n",
    "#test_data = test_data.drop('ID', axis=1)\n",
    "\n",
    "print(f\"Train set size: {len(train_data)}\") \n",
    "print(f\"Validation set size: {len(val_data)}\") \n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "      <th>dim5</th>\n",
       "      <th>dim6</th>\n",
       "      <th>dim7</th>\n",
       "      <th>dim8</th>\n",
       "      <th>dim9</th>\n",
       "      <th>...</th>\n",
       "      <th>dim23</th>\n",
       "      <th>dim24</th>\n",
       "      <th>dim25</th>\n",
       "      <th>dim26</th>\n",
       "      <th>dim27</th>\n",
       "      <th>dim28</th>\n",
       "      <th>dim29</th>\n",
       "      <th>dim30</th>\n",
       "      <th>dim31</th>\n",
       "      <th>dim32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-1000021</td>\n",
       "      <td>23.591688</td>\n",
       "      <td>-34.179787</td>\n",
       "      <td>-13.138007</td>\n",
       "      <td>-5.852693</td>\n",
       "      <td>-17.080248</td>\n",
       "      <td>2.921948</td>\n",
       "      <td>7.086022</td>\n",
       "      <td>11.879954</td>\n",
       "      <td>2.124793</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.075867</td>\n",
       "      <td>34.400513</td>\n",
       "      <td>-16.015812</td>\n",
       "      <td>-8.731407</td>\n",
       "      <td>26.657213</td>\n",
       "      <td>-21.295017</td>\n",
       "      <td>7.269122</td>\n",
       "      <td>-29.090183</td>\n",
       "      <td>-18.034906</td>\n",
       "      <td>-2.400088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-1000325</td>\n",
       "      <td>43.945010</td>\n",
       "      <td>-39.637356</td>\n",
       "      <td>2.319227</td>\n",
       "      <td>-27.171787</td>\n",
       "      <td>62.515137</td>\n",
       "      <td>28.131823</td>\n",
       "      <td>3.678916</td>\n",
       "      <td>-7.924970</td>\n",
       "      <td>13.552408</td>\n",
       "      <td>...</td>\n",
       "      <td>30.171541</td>\n",
       "      <td>-38.583240</td>\n",
       "      <td>-11.151360</td>\n",
       "      <td>3.457533</td>\n",
       "      <td>-18.338762</td>\n",
       "      <td>-14.182381</td>\n",
       "      <td>10.836757</td>\n",
       "      <td>-8.103463</td>\n",
       "      <td>13.514843</td>\n",
       "      <td>-26.685957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-1000575</td>\n",
       "      <td>20.676880</td>\n",
       "      <td>-5.101880</td>\n",
       "      <td>8.129474</td>\n",
       "      <td>-18.579628</td>\n",
       "      <td>36.006264</td>\n",
       "      <td>-2.904237</td>\n",
       "      <td>-30.171307</td>\n",
       "      <td>-25.443160</td>\n",
       "      <td>-49.994960</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.555567</td>\n",
       "      <td>12.490367</td>\n",
       "      <td>-9.332810</td>\n",
       "      <td>-8.427656</td>\n",
       "      <td>2.542956</td>\n",
       "      <td>-5.423203</td>\n",
       "      <td>33.596405</td>\n",
       "      <td>11.949966</td>\n",
       "      <td>36.587830</td>\n",
       "      <td>-6.631192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       dim1       dim2       dim3       dim4       dim5  \\\n",
       "0  sub-1000021  23.591688 -34.179787 -13.138007  -5.852693 -17.080248   \n",
       "1  sub-1000325  43.945010 -39.637356   2.319227 -27.171787  62.515137   \n",
       "2  sub-1000575  20.676880  -5.101880   8.129474 -18.579628  36.006264   \n",
       "\n",
       "        dim6       dim7       dim8       dim9  ...      dim23      dim24  \\\n",
       "0   2.921948   7.086022  11.879954   2.124793  ... -47.075867  34.400513   \n",
       "1  28.131823   3.678916  -7.924970  13.552408  ...  30.171541 -38.583240   \n",
       "2  -2.904237 -30.171307 -25.443160 -49.994960  ... -25.555567  12.490367   \n",
       "\n",
       "       dim25     dim26      dim27      dim28      dim29      dim30      dim31  \\\n",
       "0 -16.015812 -8.731407  26.657213 -21.295017   7.269122 -29.090183 -18.034906   \n",
       "1 -11.151360  3.457533 -18.338762 -14.182381  10.836757  -8.103463  13.514843   \n",
       "2  -9.332810 -8.427656   2.542956  -5.423203  33.596405  11.949966  36.587830   \n",
       "\n",
       "       dim32  \n",
       "0  -2.400088  \n",
       "1 -26.685957  \n",
       "2  -6.631192  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/neurospin/dico/data/deep_folding/current/datasets/UkBioBank40/crops/2mm/CINGULATE./mask/Rskeleton.npy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info['numpy_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21904\n",
      "Sample 0\n",
      "  Latent: 32\n",
      "  Volume shape: 21904\n",
      "Sample 1\n",
      "  Latent: 32\n",
      "  Volume shape: 21904\n",
      "Sample 2\n",
      "  Latent: 32\n",
      "  Volume shape: 21904\n",
      "Sample 3\n",
      "  Latent: 32\n",
      "  Volume shape: 21904\n",
      "Sample 4\n",
      "  Latent: 32\n",
      "  Volume shape: 21904\n",
      "Sample 5\n",
      "  Latent: 32\n",
      "  Volume shape: 21904\n"
     ]
    }
   ],
   "source": [
    "from dataloader import LatentTargetDataset\n",
    "\n",
    "sbu_list = [\"sub-1003534\", \"sub-1000715\", \"sub-1006724\", \"sub-1004594\", \"sub-1002539\" , \"sub-1005312\", ]\n",
    "list_indi = [29, 5, 58, 36, 14, 45]\n",
    "\n",
    "dataset = LatentTargetDataset(\n",
    "    latent_csv_path=train_path,\n",
    "    target_npy_path=dataset_info['numpy_all'],\n",
    "    subjects_all_path=dataset_info['subjects_all'],\n",
    "    subject_list=sbu_list\n",
    ")\n",
    "\n",
    "print(16*37*37)\n",
    "\n",
    "# Test shape and values\n",
    "for i in range(len(dataset)):\n",
    "    latent, volume = dataset[i]\n",
    "    print(f\"Sample {i}\")\n",
    "    print(f\"  Latent: {(latent==torch.tensor((train_data[train_data['ID']==sbu_list[i]].drop('ID', axis=1)).values, dtype=torch.float32)).sum()}\")\n",
    "    print(f\"  Volume shape: {(volume == torch.tensor(skels[list_indi[i]],dtype=torch.float32).permute(3, 2, 1, 0)).sum()}\")  # Should be [C, D, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32]) torch.Size([32, 1, 16, 37, 37])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataModule_Learning\n",
    "\n",
    "# Load configs\n",
    "decoder_cfg = OmegaConf.load(\"../configs/config.yaml\")\n",
    "encoder_config_path = os.path.join(decoder_cfg.model_to_decode_path, \".hydra\", \"config.yaml\")\n",
    "encoder_cfg = OmegaConf.load(encoder_config_path)\n",
    "encoder_cfg[\"dataset_folder\"] = decoder_cfg[\"dataset_folder\"]\n",
    "region = list(encoder_cfg.dataset.keys())[0]\n",
    "dataset_info = OmegaConf.to_container(encoder_cfg.dataset[region], resolve=True)\n",
    "\n",
    "# Instantiate and setup the datamodule\n",
    "dm = DataModule_Learning(decoder_cfg, dataset_info)\n",
    "dm.setup()\n",
    "\n",
    "# Get the data loaders\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "# Example loop\n",
    "for latent_vector, target_volume in train_loader:\n",
    "    print(latent_vector.shape, target_volume.shape)\n",
    "    break  # Just show one batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decodervenv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
